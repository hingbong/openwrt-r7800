--- a/drivers/clk/qcom/Makefile
+++ b/drivers/clk/qcom/Makefile
@@ -14,6 +14,7 @@ clk-qcom-$(CONFIG_KRAIT_CLOCKS) += clk-k
 clk-qcom-y += clk-hfpll.o
 clk-qcom-y += reset.o
 clk-qcom-$(CONFIG_QCOM_GDSC) += gdsc.o
+clk-qcom-y += fab_scaling.o
 
 # Keep alphabetically sorted by config
 obj-$(CONFIG_APQ_GCC_8084) += gcc-apq8084.o
--- /dev/null
+++ b/drivers/clk/qcom/fab_scaling.c
@@ -0,0 +1,160 @@
+/*
+ * Copyright (c) 2015, The Linux Foundation. All rights reserved.
+ *
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
+ * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
+ * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
+ * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ */
+
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/platform_device.h>
+#include <linux/err.h>
+#include <linux/io.h>
+#include <linux/of.h>
+#include <linux/of_device.h>
+#include <linux/clk.h>
+#include <linux/clk-provider.h>
+#include <linux/fab_scaling.h>
+
+#define APPS_FAB_CLK	"apps-fab-clk"
+#define DDR_FAB_CLK	"ddr-fab-clk"
+
+static u32 fab_freq_high;
+static u32 fab_freq_nominal;
+static u32 cpu_freq_threshold;
+static u32 fab_cur_freq = 0;
+
+static struct clk *apps_fab_clk;
+static struct clk *ddr_fab_clk;
+
+void scale_fabrics(unsigned long max_cpu_freq)
+{	
+	unsigned long new_freq;
+
+	if (!apps_fab_clk || !ddr_fab_clk)
+		return;
+
+	if (max_cpu_freq > cpu_freq_threshold)
+		new_freq = fab_freq_high;
+	else
+		new_freq = fab_freq_nominal;
+
+	if (new_freq != fab_cur_freq) {
+		clk_set_rate(apps_fab_clk, new_freq);
+		clk_set_rate(ddr_fab_clk, new_freq);
+		fab_cur_freq = new_freq;
+	}
+
+	return;
+}
+EXPORT_SYMBOL(scale_fabrics);
+
+static int ipq806x_fab_scaling_probe(struct platform_device *pdev)
+{
+	struct device_node *np = pdev->dev.of_node;
+	int ret;
+
+	if (!np)
+		return -ENODEV;
+
+	if (of_property_read_u32(np, "fab_freq_high", &fab_freq_high)) {
+		pr_err("FABRICS turbo freq not found. Using defaults...\n");
+		fab_freq_high = 533000000;
+	}
+
+	if (of_property_read_u32(np, "fab_freq_nominal", &fab_freq_nominal)) {
+		pr_err("FABRICS nominal freq not found. Using defaults...\n");
+		fab_freq_nominal = 400000000;
+	}
+
+	if (of_property_read_u32(np, "cpu_freq_threshold", &cpu_freq_threshold)) {
+		pr_err("FABRICS cpu freq threshold not found. Using defaults...\n");
+		cpu_freq_threshold = 1000000000;
+	}
+
+	apps_fab_clk = devm_clk_get(&pdev->dev, APPS_FAB_CLK);
+	ret = PTR_ERR_OR_ZERO(apps_fab_clk);
+	if (ret) {
+		/*
+		 * If apps fab clk node is present, but clock is not yet
+		 * registered, we should try defering probe.
+		 */
+		if (ret == -EPROBE_DEFER) {
+			pr_warn("APPS FABRIC clock is not ready, retry\n");
+			return ret;
+		} else {
+			pr_err("Failed to get APPS FABRIC clock: %d\n", ret);
+			apps_fab_clk = 0;
+			return -ENODEV;
+		}
+	}
+
+	clk_set_rate(apps_fab_clk, fab_freq_nominal);
+	clk_prepare_enable(apps_fab_clk);
+
+	ddr_fab_clk = devm_clk_get(&pdev->dev, DDR_FAB_CLK);
+	ret = PTR_ERR_OR_ZERO(ddr_fab_clk);
+	if (ret) {
+		/*
+		 * If ddr fab clk node is present, but clock is not yet
+		 * registered, we should try defering probe.
+		 */
+		if (ret == -EPROBE_DEFER) {
+			pr_warn("DDR FABRIC clock is not ready, retry\n");
+			return ret;
+		} else {
+			pr_err("Failed to get DDR FABRIC clock: %d\n", ret);
+			ddr_fab_clk = 0;
+			return -ENODEV;
+		}
+	}
+
+	clk_set_rate(ddr_fab_clk, fab_freq_nominal);
+	clk_prepare_enable(ddr_fab_clk);
+
+	return 0;
+}
+
+static int ipq806x_fab_scaling_remove(struct platform_device *pdev)
+{
+	cpu_freq_threshold = 0;
+
+	return 0;
+}
+
+static const struct of_device_id fab_scaling_ipq806x_match_table[] = {
+	{ .compatible = "qcom,fab-scaling" },
+	{ }
+};
+
+static struct platform_driver fab_scaling_ipq806x_driver = {
+	.probe		= ipq806x_fab_scaling_probe,
+	.remove		= ipq806x_fab_scaling_remove,
+	.driver		= {
+		.name   = "fab-scaling",
+		.owner  = THIS_MODULE,
+		.of_match_table = fab_scaling_ipq806x_match_table,
+	},
+};
+
+static int __init fab_scaling_ipq806x_init(void)
+{
+	return platform_driver_register(&fab_scaling_ipq806x_driver);
+}
+late_initcall(fab_scaling_ipq806x_init);
+
+static void __exit fab_scaling_ipq806x_exit(void)
+{
+	platform_driver_unregister(&fab_scaling_ipq806x_driver);
+}
+module_exit(fab_scaling_ipq806x_exit);
--- a/drivers/cpufreq/cpufreq-dt.c
+++ b/drivers/cpufreq/cpufreq-dt.c
@@ -24,9 +24,12 @@
 #include <linux/regulator/consumer.h>
 #include <linux/slab.h>
 #include <linux/thermal.h>
+#include <linux/fab_scaling.h>
 
 #include "cpufreq-dt.h"
 
+static DEFINE_PER_CPU(struct clk *, cpu_cores_clks);
+
 struct private_data {
 	struct opp_table *opp_table;
 	struct device *cpu_dev;
@@ -44,9 +47,70 @@ static struct freq_attr *cpufreq_dt_attr
 static int set_target(struct cpufreq_policy *policy, unsigned int index)
 {
 	struct private_data *priv = policy->driver_data;
+	struct clk *l2_clk = policy->l2_clk;
+	struct regulator *l2_regulator = policy->l2_regulator;
+	unsigned long target_freq = policy->freq_table[index].frequency * 1000;
+	int ret;
+	
+	ret = dev_pm_opp_set_rate(priv->cpu_dev, target_freq);
+
+	if (!ret) {
+		unsigned long max_cpu_freq = max(target_freq,
+						 clk_get_rate(per_cpu(cpu_cores_clks, !policy->cpu)));
+		
+		if (policy->l2_rate_set) {
+			unsigned long new_l2_freq = 0, new_l2_volt = 0;
+			static unsigned long last_l2_freq = 0;
+			static unsigned long last_l2_volt[2] = {};
+			int i, tol = 0;
+
+			/* Unlike regulators, clock rate is adjusted on any request. Let's pick
+			 * the highest core frequency and set the L2 cache frequency, so we 
+			 * don't pull the L2 cache frequency down prematurely if either cores is 
+			 * running at max.
+			 */
+
+			for (i = 2; i >= 0; i--) {
+				if (max_cpu_freq >= policy->l2_cpufreq[i]) {
+					new_l2_freq = policy->l2_rate[i];
+
+					if (last_l2_freq != new_l2_freq) {
+						clk_set_rate(l2_clk, new_l2_freq);
+						last_l2_freq = new_l2_freq;
+					}
+
+					break;
+				}
+			}
+
+			/* L2 cache supply has a single regulator shared by cores and each core
+			 * registers itself as a regulator consumer. N of consumers = N of cores.
+			 * Regulator driver sets the regulator output to highest voltage requested
+			 * among all consumers. We set the regulator voltage per core and let the
+			 * driver set the highest voltage requested - either core can be running
+			 * at max and l2 cache should get the needed voltage.
+			 */
+			if (policy->l2_volt_set) {
+				for (i = 2; i >= 0; i--) {
+					if (target_freq >= policy->l2_cpufreq[i]) {
+						tol = policy->l2_volt[i] * policy->l2_volt_tol / 100;
+						new_l2_volt = policy->l2_volt[i];
+
+						if (last_l2_volt[policy->cpu] != new_l2_volt) {
+							regulator_set_voltage_tol(l2_regulator,new_l2_volt,tol);
+							last_l2_volt[policy->cpu] = new_l2_volt;
+						}
+
+						break;
+					}
+				}
+			}
+		}
+
+		scale_fabrics(max_cpu_freq);
+	}
 
-	return dev_pm_opp_set_rate(priv->cpu_dev,
-				   policy->freq_table[index].frequency * 1000);
+	return ret;
 }
 
 /*
@@ -149,18 +213,24 @@ static int cpufreq_init(struct cpufreq_p
 	struct private_data *priv;
 	struct device *cpu_dev;
 	struct clk *cpu_clk;
+	struct clk *l2_clk = NULL;
+	struct regulator *l2_regulator = NULL;
+	struct device_node *np, *cache;
 	unsigned int transition_latency;
 	bool fallback = false;
 	const char *name;
-	int ret;
-
+	int ret, cpu;
+	
 	cpu_dev = get_cpu_device(policy->cpu);
 	if (!cpu_dev) {
 		pr_err("failed to get cpu%d device\n", policy->cpu);
 		return -ENODEV;
 	}
 
-	cpu_clk = clk_get(cpu_dev, NULL);
+	for_each_possible_cpu(cpu)
+		per_cpu(cpu_cores_clks, cpu) = clk_get(get_cpu_device(cpu), NULL);
+
+	cpu_clk = per_cpu(cpu_cores_clks, policy->cpu);
 	if (IS_ERR(cpu_clk)) {
 		ret = PTR_ERR(cpu_clk);
 		dev_err(cpu_dev, "%s: failed to get clk: %d\n", __func__, ret);
@@ -281,6 +351,58 @@ static int cpufreq_init(struct cpufreq_p
 	policy->cpuinfo.transition_latency = transition_latency;
 	policy->dvfs_possible_from_any_cpu = true;
 
+	l2_clk = devm_clk_get(cpu_dev, "l2");
+	if (!IS_ERR(l2_clk)) {
+		policy->l2_clk = l2_clk;
+
+		np = of_node_get(priv->cpu_dev->of_node);
+		if (np) {
+			of_property_read_u32(np, "voltage-tolerance", &policy->l2_volt_tol);
+			cache = of_find_next_cache_node(np);
+		}
+	}
+
+	policy->l2_rate_set = false;
+	policy->l2_volt_set = false;
+
+	if (cache) {
+		struct device_node *vdd;
+	
+		of_property_read_u32_array(cache, "l2-rates", policy->l2_rate, 3);
+		if (policy->l2_rate[0] && policy->l2_rate[1] && policy->l2_rate[2]) {
+			policy->l2_rate_set = true;
+			of_property_read_u32_array(cache, "l2-cpufreq", policy->l2_cpufreq, 3);
+			of_property_read_u32_array(cache, "l2-volt", policy->l2_volt, 3);
+		} else
+			pr_warn("L2: failed to parse L2 rates\n");
+			
+		if (!policy->l2_cpufreq[0] && !policy->l2_cpufreq[1] && 
+			!policy->l2_cpufreq[2] && policy->l2_rate_set) {
+			int i;
+			
+			pr_warn("L2: failed to parse target cpu freq, using defaults\n");
+			for (i = 0; i < 3; i++)
+				policy->l2_cpufreq[i] = policy->l2_rate[i];
+		}
+
+		if (policy->l2_volt[0] && policy->l2_volt[1] && policy->l2_volt[2] &&
+			policy->l2_volt_tol && policy->l2_rate_set)
+			vdd = of_parse_phandle(cache, "l2-supply", 0);
+			
+		if (vdd) {
+			l2_regulator = devm_regulator_get(cpu_dev, vdd->name);
+			if (!IS_ERR(l2_regulator)) {
+				policy->l2_regulator = l2_regulator;
+				policy->l2_volt_set = true;
+			} else {
+				pr_warn("failed to get l2 supply\n");
+				l2_regulator = NULL;
+			}
+
+			of_node_put(vdd);
+		}
+	}
+
 	return 0;
 
 out_free_cpufreq_table:
--- a/include/linux/cpufreq.h
+++ b/include/linux/cpufreq.h
@@ -73,6 +73,16 @@ struct cpufreq_policy {
 	unsigned int		cpu;    /* cpu managing this policy, must be online */
 
 	struct clk		*clk;
+
+	struct clk			*l2_clk; /* L2 clock */
+	struct regulator	*l2_regulator; /* L2 supply */
+	unsigned int		l2_rate[3]; /* L2 bus clock rate */
+	bool				l2_rate_set;
+	unsigned int		l2_cpufreq[3]; /* L2 target CPU frequency */
+	unsigned int		l2_volt[3]; /* L2 voltage array */
+	bool				l2_volt_set;
+	unsigned int		l2_volt_tol; /* L2 voltage tolerance */
+
 	struct cpufreq_cpuinfo	cpuinfo;/* see above */
 
 	unsigned int		min;    /* in kHz */
--- /dev/null
+++ b/include/linux/fab_scaling.h
@@ -0,0 +1,31 @@
+/*
+ * Copyright (c) 2015, The Linux Foundation. All rights reserved.
+ *
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
+ * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
+ * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
+ * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ */
+
+
+#ifndef __FAB_SCALING_H
+#define __FAB_SCALING_H
+
+/**
+ * scale_fabrics - Scale DDR and APPS FABRICS
+ *
+ * This function monitors all the registered clocks and does APPS
+ * and DDR FABRIC scaling based on the idle frequencies with which
+ * it was registered.
+ *
+ */
+void scale_fabrics(unsigned long max_cpu_freq);
+
+#endif
